# Optical Flow Cluster Analyzer (OFCA)

A desktop GUI for **human movement analysis** that combines **YOLOv8 person detection**, **Lucas‚ÄìKanade optical flow**, and **unsupervised clustering** to characterize motion patterns and movement quality (e.g., *fluidity*, *consistency*, origin of motion). Built with **PyQt6** and **OpenCV**.

> This README documents the refactored app found in: `Human movement analysis/ofca_project/`  
> A legacy single-file prototype also exists at: `Human movement analysis/Human origin movement analysis.py`.

---

## ‚ú® Key Features

- **Video/Webcam ingestion** with frame-by-frame processing.
- **Person detection** via **Ultralytics YOLOv8** (`HumanDetector`).
- **Optical flow** via **Lucas‚ÄìKanade** (`OpticalFlowProcessor`).
- **Clustering** of flow vectors with **K-Means / DBSCAN / Agglomerative / OPTICS** (see `analysis/worker.py`).
- **Quality metrics**:
  - Hopkins statistic (clusterability proxy)
  - Magnitude/consistency summaries
  - Silhouette, Davies‚ÄìBouldin, Calinski‚ÄìHarabasz indices
- **Interactive GUI** (PyQt6):
  - Live video view, dashboards, and result tabs (`ui/tabs.py`)
  - Validation dialog to compare automatic vs ground-truth labels
  - Export of reports/CSV (see `io/reporting.py`)
- **Visualization helpers**: motion trails, heatmaps, cluster centroids (`utils/visuals.py`).
- **Threaded analysis worker** to keep the UI responsive (`analysis/worker.py`).

---

## üì¶ Project Structure (refactored)

```
ofca_project/
‚îú‚îÄ main.py                  # Entry point (PyQt6 app)
‚îú‚îÄ requirements.txt         # Minimal runtime deps for ofca_project
‚îú‚îÄ ofca/
‚îÇ  ‚îú‚îÄ app.py                # QMainWindow: OpticalFlowClusterAnalyzer
‚îÇ  ‚îú‚îÄ analysis/
‚îÇ  ‚îÇ  ‚îú‚îÄ movement_quality.py  # MovementQualityAnalyzer (RF, stats, thresholds)
‚îÇ  ‚îÇ  ‚îú‚îÄ fluid_motion.py      # FluidMotionAnalyzer (Hopkins-based fluidity)
‚îÇ  ‚îÇ  ‚îî‚îÄ worker.py            # QThread for clustering + metrics
‚îÇ  ‚îú‚îÄ vision/
‚îÇ  ‚îÇ  ‚îú‚îÄ detector.py          # YOLOv8 person detection
‚îÇ  ‚îÇ  ‚îî‚îÄ optical_flow.py      # Lucas‚ÄìKanade optical flow pipeline
‚îÇ  ‚îú‚îÄ ui/
‚îÇ  ‚îÇ  ‚îú‚îÄ dialogs.py           # Validation results & helpers
‚îÇ  ‚îÇ  ‚îú‚îÄ tabs.py              # Video / Dashboard / Results tabs
‚îÇ  ‚îÇ  ‚îî‚îÄ style.py             # Fonts and style helpers
‚îÇ  ‚îú‚îÄ utils/
‚îÇ  ‚îÇ  ‚îú‚îÄ metrics.py           # Hopkins, indices, helpers
‚îÇ  ‚îÇ  ‚îú‚îÄ visuals.py           # Trails, heatmaps, centroids
‚îÇ  ‚îÇ  ‚îî‚îÄ tables.py            # QTable helpers
‚îÇ  ‚îî‚îÄ _legacy/
‚îÇ     ‚îî‚îÄ Human origin movement analyzer.py  # backup of the old monolith
‚îî‚îÄ (optional) yolov8n.pt     # If present, used for detection; otherwise auto-download
```

The repository root also contains:
- `Human movement analysis/requirements.txt` ‚Äî a **larger** dependency set used during experimentation (includes `ultralytics`).
- `Human movement analysis/Human origin movement analysis.py` ‚Äî the **legacy single-file UI**.

---

## üõ†Ô∏è Requirements

- Python **3.10+** recommended
- OS: Windows / macOS / Linux
- GPU optional (YOLOv8 will use CUDA if available)
- **Important**: The refactored app uses **PyQt6**. Make sure your environment matches.

### Minimal install (recommended for the refactored app)

```bash
cd "Human movement analysis/ofca_project"
python -m venv .venv
# On macOS/Linux
. .venv/bin/activate
# On Windows
# .venv\Scripts\activate

pip install --upgrade pip
pip install -r requirements.txt
pip install ultralytics  # YOLOv8 (if not already in requirements)
```

> If you get import errors for `PyQt6` but your `requirements.txt` pins **PyQt5**, update it to `PyQt6==6.6.*` (or compatible) because the code imports from `PyQt6`.

---

## ‚ñ∂Ô∏è Run

```bash
cd "Human origin movement analysis.py"
```

The GUI will open:
1. Choose a **video file** (or enable **webcam**).
2. Select a **detection model size** (n/s/m/l) if applicable.
3. Start processing to see optical flow vectors, clusters, and quality metrics update live.

---

## üî¨ How It Works (Pipeline)

1. **Detection** ‚Äì `vision/detector.py`
   - Loads a YOLOv8 model (e.g., `yolov8n.pt`).
   - Detects person bounding boxes per frame.

2. **Tracking & Flow** ‚Äì `vision/optical_flow.py`
   - Samples feature points (Shi‚ÄìTomasi).
   - Computes point trajectories with Lucas‚ÄìKanade optical flow pyramids.
   - Emits per-frame **flow_points** (dx, dy, positions) and derived metrics.

3. **Clustering & Metrics** ‚Äì `analysis/worker.py`
   - Stacks flow vectors across a window; runs KMeans/DBSCAN/Agglomerative/OPTICS.
   - Computes **silhouette**, **DB**, **CH** indices, and **Hopkins** (via `utils/metrics.py`).

4. **Movement Quality** ‚Äì `analysis/movement_quality.py` & `analysis/fluid_motion.py`
   - Applies thresholds for **fluidity**, **magnitude**, **consistency**.
   - Optionally trains a **RandomForest** on labeled sessions (for auto-labeling).
   - Tracks motion origins and proof frames.

5. **UI** ‚Äì `ofca/app.py` + `ui/tabs.py`
   - Video tab (preview), Dashboard tab (metrics), Result tab (clusters & validation).
   - Export reports and compare with **ground-truth CSV** (see `io/reporting.py`, `ui/dialogs.py`).

---

## üìÅ Data & File Formats

- **Input**: Any video readable by OpenCV (mp4, avi, mov) or a Webcam stream.
- **Ground truth** (optional): A CSV/JSON file mapping **frame ranges ‚Üí labels**.
- **Exports**: CSV summaries (metrics per window), optional PNGs of snapshots/heatmaps.

---

## ‚öôÔ∏è Configuration Tips

- **Model weights**: If `yolov8n.pt` is in the project folder, it will be used; otherwise, Ultralytics will download weights.
- **Performance**: Environment variable `OMP_NUM_THREADS=1` is set to avoid KMeans warnings and oversubscription.
- **Sampling**: Adjust max corners, LK window size, and pyramid levels in `vision/optical_flow.py`.
- **Clustering**: For noisy scenes, try **DBSCAN** (tune `eps`, `min_samples`). For compact motions, **KMeans** works well.

---

## üß™ Reproducible Experiments

- Use a fixed random seed in metrics/clustering for reproducibility when benchmarking.
- Save **per-frame** features to CSV and compute aggregate metrics offline for ablation.

---

## üöß Known Issues / To‚ÄëDos

- **PyQt version**: Some files import `PyQt6` while an older `requirements.txt` pins `PyQt5`.  
  **Action**: Standardize on **PyQt6** in `ofca_project/requirements.txt`.
- **Large assets**: Model weights (`*.pt`) and videos **should not** be committed to git.  
  **Action**: Add them to `.gitignore` or provide download instructions.
- **Docs**: Add screenshots/GIFs of the GUI to improve the README.
- **Tests**: Add unit tests for `utils.metrics` and `vision` modules.

---

## üß∞ Development

```bash
# Lint
pip install ruff black
ruff check ofca
black ofca

# Run in dev
python main.py
```

---

## ü§ù Contributing

PRs are welcome! If you add a new clustering method or metric:
- Place algorithms in `ofca/analysis/` or `ofca/utils/`.
- Expose controls in `ui/tabs.py`.
- Update this README and the in‚Äëapp help.

---

---

## ‚úçÔ∏è Citation

If you use **OFCA** in academic work:

```
@software{ofca_2025,
  author  = {{Abdullaj Al Foysal}},
  title   = {{Optical Flow Cluster Analyzer (OFCA)}},
  year    = {{2025}},
  url     = {{https://github.com/<Foysal440>/Origin-of-Human-Movement}}
}
```

---

##  Acknowledgments

- Built with **OpenCV**, **PyQt6**, **scikit‚Äëlearn**, and **Ultralytics YOLOv8**.
- Thanks to collaborators and reviewers for feedback on movement quality metrics and validation UI.

---
